n8n Popularity System

FastAPI service for collecting, aggregating, and serving popularity data of n8n workflows from multiple public platforms.
Currently supports: YouTube, n8n Forum, StackOverflow.

âœ¨ Features

Multi-source collection: YouTube, Forum, StackOverflow (Google planned)

Automatic merging of results into a single dataset (all_data.json)

Popularity scoring per workflow (views, likes, comments, votes, ratios)

JSON outputs for each source + unified dataset

REST API (FastAPI) to browse, query, and serve results

Environment-based config (.env)

ğŸ“‚ Project Structure
n8n-popularity-system/
â”‚â”€â”€ app/
â”‚   â”œâ”€â”€ crud.py            # Database operations
â”‚   â”œâ”€â”€ database.py        # SQLite setup (SQLAlchemy)
â”‚   â”œâ”€â”€ fetch_data.py      # Orchestrates collection & merging
â”‚   â”œâ”€â”€ forum.py           # Forum scraper
â”‚   â”œâ”€â”€ main.py            # FastAPI entrypoint
â”‚   â”œâ”€â”€ models.py          # SQLAlchemy models
â”‚   â”œâ”€â”€ stackoverflow.py   # StackOverflow fetcher
â”‚   â”œâ”€â”€ utils.py           # Helpers
â”‚   â”œâ”€â”€ youtube.py         # YouTube fetcher
â”‚â”€â”€ output/                # JSON snapshots
â”‚   â”œâ”€â”€ all_data.json
â”‚   â”œâ”€â”€ forum.json
â”‚   â”œâ”€â”€ stackoverflow.json
â”‚   â”œâ”€â”€ youtube.json
â”‚â”€â”€ .env                   # Local config (ignored in git)
â”‚â”€â”€ .env.example           # Example env config
â”‚â”€â”€ requirements.txt       # Dependencies
â”‚â”€â”€ README.md              # Documentation

âš™ï¸ Setup
1. Clone repo
git clone <your-repo-url>
cd n8n-popularity-system

2. Create virtual environment
python -m venv .venv
source .venv/bin/activate   # Mac/Linux
.venv\Scripts\activate      # Windows

3. Install dependencies
pip install -r requirements.txt

4. Setup environment variables

Copy .env.example â†’ .env and fill in required values.

cp .env.example .env

ğŸ”‘ Environment Variables
Variable	Description
YOUTUBE_API_KEY	API key for YouTube Data API (required for live fetching)

(Forum & StackOverflow fetchers run without keys.)

ğŸ“¡ Data Collection

Run the collector:

python -m app.fetch_data


This will fetch fresh data and update JSON files in output/:

youtube.json

forum.json

stackoverflow.json

all_data.json (merged + deduped)

ğŸ—„ï¸ Output Format

Each JSON file is a list of workflow entries:

{
  "workflow": "Email Automation with Gmail",
  "platform": "YouTube",
  "country": "Global",
  "evidence": "https://youtube.com/watch?v=XXXX",
  "popularity_score": 87
}


Fields:

workflow â†’ Workflow title

platform â†’ Source platform

country â†’ Country if available, else "Global"

evidence â†’ URL or reference

popularity_score â†’ Computed score

ğŸ§® Scoring

Each source has its own formula:

Source	Formula
YouTube	0.45*views + 0.25*likes + 0.15*comments + 0.15*like_to_view_ratio
Forum	0.4*views + 0.3*likes + 0.3*comments
StackOverflow	Based on votes + answer_count + view_count (weighted)

Final popularity_score is normalized and comparable across sources.

ğŸš€ Running the API

Start the server:

uvicorn app.main:app --reload


Visit:

Swagger UI â†’ http://localhost:8000/docs

ReDoc â†’ http://localhost:8000/redoc

ğŸ”Œ API Endpoints
Endpoint	Method	Description
/	GET	Health check / metadata
/workflows	GET	Get all workflows (from all_data.json)
/workflows/{platform}	GET	Get workflows from specific platform (youtube, forum, stackoverflow)

Example:

curl http://127.0.0.1:8000/workflows/youtube

âœ… Deliverables

Working FastAPI service

Dataset of 50+ workflows across multiple sources (output/all_data.json)

Scoring formulas for each platform

Documentation (this README)

ğŸ”® Next Steps

Add Google Trends as data source

Add Reddit & GitHub collectors

Improve scoring via time-based weighting

Export in CSV / JSONL history